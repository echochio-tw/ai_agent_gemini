import gradio as gr
import google.generativeai as genai
import os
import subprocess

# --- 1. é…ç½® Gemini API ---
# ä»ç¯å¢ƒå˜é‡ä¸­è·å– API Key
GEMINI_API_KEY = 'AIzaSyBUSS3XXXXXXXXXXXXXXXXXXXXXXX'

genai.configure(api_key=GEMINI_API_KEY)

# --- 2. å®šä¹‰å·¥å…·å‡½æ•° ---
def execute_shell_command(command: str):
    """
    Executes a shell command in the environment and returns the output.
    """
    try:
        # ä½¿ç”¨ shell=True å…è®¸æ‰§è¡Œ shell å‘½ä»¤
        result = subprocess.run(
            command, 
            shell=True, 
            capture_output=True, 
            text=True, 
            encoding='utf-8' # ç¡®ä¿æ­£ç¡®å¤„ç†å‘½ä»¤è¾“å‡ºä¸­çš„å­—ç¬¦
        )
        output = result.stdout.strip()
        error = result.stderr.strip()
        return_code = result.returncode

        if return_code != 0:
            return (
                f"Command failed with return code {return_code}.\n"
                f"Output: {output}\n"
                f"Error: {error}"
            )
        
        return output if output else "Command executed successfully (no output)."
        
    except Exception as e:
        return f"Error executing command: {str(e)}"

# åˆå§‹åŒ– Gemini æ¨¡å‹
model = genai.GenerativeModel(
    'models/gemini-2.5-flash', 
    tools=[execute_shell_command]
)

# --- 3. Gradio èŠå¤©å‡½æ•° (æ ¸å¿ƒé€»è¾‘) ---
def chat_with_gemini(message, history):
    # åˆå§‹åŒ–èŠå¤©ä¼šè¯
    if not hasattr(chat_with_gemini, 'chat_session'):
        chat_with_gemini.chat_session = model.start_chat()

    try:
        # 1. ç¬¬ä¸€æ¬¡å‘é€æ¶ˆæ¯ç»™ Gemini
        response = chat_with_gemini.chat_session.send_message(message)

        # 2. å¾ªç¯å¤„ç†æ¨¡å‹è¦æ±‚çš„æ‰€æœ‰å·¥å…·è°ƒç”¨ (ä½¿ç”¨ response.parts æ£€æŸ¥å…¼å®¹æ‰€æœ‰SDKç‰ˆæœ¬ï¼ŒåŒ…æ‹¬ 0.8.5)
        # åªè¦å“åº”ä¸­åŒ…å« function_call partï¼Œå°±ç»§ç»­å¾ªç¯
        while any(part.function_call for part in response.parts):
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª function_call part
            function_call_part = next(
                (part for part in response.parts if part.function_call), None
            )

            if function_call_part is None:
                break

            tool_call = function_call_part.function_call
            tool_name = tool_call.name
            
            # åœ¨ 0.8.5 ç‰ˆæœ¬ä¸­ï¼Œtool_call.args æ˜¯ä¸€ä¸ªæ˜ å°„ç±»å‹ï¼Œéœ€è¦è½¬æ¢ä¸º dict
            tool_args = dict(tool_call.args) 

            if tool_name == "execute_shell_command":
                # æ‰§è¡Œå·¥å…·å¹¶è·å–ç»“æœ
                tool_output = execute_shell_command(**tool_args)
                
                # ğŸ› ï¸ å…¼å®¹ 0.8.5 ä¿®å¤ï¼šä½¿ç”¨ genai.protos æ„é€  FunctionResponse Part
                function_response_part = genai.protos.Part(
                    function_response=genai.protos.FunctionResponse(
                        name=tool_name,
                        response={"result": tool_output}
                    )
                )
                
                # å°†å·¥å…·ç»“æœå‘å›ç»™ Gemini (ç¬¬äºŒè½®æˆ–åç»­è½®æ¬¡)
                response = chat_with_gemini.chat_session.send_message(
                    function_response_part
                )
            else:
                return f"Error: Unknown tool {tool_name}"

        # 3. å¾ªç¯ç»“æŸæ—¶ï¼Œè¿”å›æœ€ç»ˆçš„æ–‡æœ¬
        # å¦‚æœæ¨¡å‹è¿”å›äº†æ–‡æœ¬ï¼Œå°±è¿”å›ï¼›å¦‚æœæ¨¡å‹åªæ˜¯è¿”å›äº†ç©ºå“åº”ï¼ŒGradio ä¹Ÿèƒ½å¤„ç†ç©ºå­—ç¬¦ä¸²ã€‚
        return response.text
        
    except Exception as e:
        return f"Error communicating with Gemini API: {str(e)}"

# --- 4. Gradio æ¥å£é…ç½® (ä¿æŒå…¼å®¹æ€§) ---
iface = gr.ChatInterface(
    chat_with_gemini,
    title="ğŸ¤– Gemini Chat with Shell Command Tool",
    description=(
        "Ask Gemini questions or input commands like **`åš ls -la /root`** to execute shell commands. "
        "Commands are run in the environment where this script is executed (e.g., WSL/Linux/Windows Shell)."
    )
)

# --- 5. è¿è¡Œç¨‹åº ---
if __name__ == "__main__":
    print("Starting Gradio interface...")
    iface.launch(share=True)
